
> [!info] Resources
> [üìä PowerPoint](MemoryVirtualisation.pdf)
> [üìΩÔ∏èLecture Recording]()

Memory virtualisation is a key mechanism to share efficiently and securely memory, through a simple programming model. #keyTermDefinition 

Memory virtualisation has evolved over the years: 
- Hardware virtualisation
- Segmentation
- Paging 

X86 memory model uses multi-table pages to effective and secure paging. 
- Table-lookaside can improve memory access time
---
OSes use spatial virtualisation to share address spaces between processes. The goals:
- **Transparency**: Programmers should be unaware if memory virtualisation
- **Efficiency**: virtualisation must not affect performance of negatively impact space allocation
- **Protection**: processes must not be able to view of edit memory areas from other programs

Throughout history:

![[Excalidraw/Drawing 2025-10-17 12.45.47.excalidraw]]

---
## Memory Components

- **Physical Memory**: The set of actual addresses of bytes on the RAM chips of a computer.
- **Virtual Memory**: The set of addresses visible to a process.
- **Process Address Space**: The range of addresses visible by a process.
	- **Static**: Code and global variables
	- **Dynamic**: The stack, head.
- **Memory Management**: A hardware component of the CPU that translates virtual pages to physical memory frames

 Why do we need dynamic memory?:
 - The amount of required memory may be task-dependent
 - Input size may be unknown at compile time
 - Conservative pre-allocation would be wasteful
 - Recursive functions (invocation frames)
---
## MV: Base And Bounds

Hardware-based address translation using base and bounds; was the first attempt for memory virtualization. 
- Use two registers: a base register stores the start address in physical memory and bound stores the size. 
- Separate Physical Memory into dynamic blocks called pages.
- Each process is allocated a page. 
- Physical address = virtual address + base

To protect memory, use an arithmetic check to control memory access. 
- ``` base_addr <= addr < base_addr + 0xFFFFF```
- Every time a process is deschedule, then the base and bound registers must be updated. 
 
Problem: internal fragmentation 
- All memory is continuously allocated 
- Waste of physical memory ‚Äì remember the large space chunk between stack and heap 
- No memory sharing between processes 
---
## Memory Virtualisation

#### Segmentation
Break physical memory into segments. 
- Each program section has a pair of base and bounds values. 
Memory sharing : Use flags to indicate if programs can read, write or execute a segment. 
- Read-only code segments shared between processes. 
- Process can access shared memory as its own virtual memory and ensure isolation.

#### Segmentation - Address Translation
- Using lots of if statements is slow to check and translate virtual to physical addresses. 
- Use bitmasks to speed up the process.

#### Segmentation - Limitations
External Fragmentation 
- When segments are variable size, free memory can become fragmented. 
- Even if free memory can satisfy a request, it may not be contiguous. 
- Memory compaction can solve the problem, but computationally expensive. 

Complex memory management 
- OS must keep track of base and limit for every segment of every process. 
- Dynamic growth (e.g., expanding the stack or heap) may require relocating other segments. 
- Makes allocation and relocation overhead high. 

Memory compaction: rearranging (shuffling) processes in memory so that all free memory is combined into one large contiguous block.

Variable size fragments creates fragmentation and fixed size memory segments waste resources.

---
## Memory Virtualisation - Paging

Memory paging: chop up space into small, fixed- sized pieces. 
- In virtual memory, this is called a page, and in physical memory, it is called a frame. 

Page table: stores physical translations for each of the virtual pages of the address space (one table per process). 
- Use bitmasks for efficient lookups. 

Example: 128-byte physical memory with eight frames of 16 bytes 
```
(Virtual Page 0 ‚Üí Physical Frame 3)
(Virtual Page 1 ‚Üí Physical Frame 7)
(Virtual Page 2 ‚Üí Physical Frame 5)
(Virtual Page 3 ‚Üí Physical Frame 2)
```
---
##  Memory Translation (Example)

- Split virtual address into two components: the virtual page number (VPN), and the offset within the page.
- Use VPN as an index in the page table to find which Physical Frame Number (PFN) has the virtual page. 
- Replace VPN with PFN in the address, and you have the physical address.
![[Pasted image 20251018112124.png]]
---
## Page table Entry

‚Ä¢ PFN: Physical frame number 
‚Ä¢ PWT, PCD, PAT, and G determine how hardware caching works for these pages 
‚Ä¢ accessed bit (A) and a dirty bit (D): used to optimize how pages are cached. 
‚Ä¢ read/write bit (R/W) which determines if writes are allowed to this page 
‚Ä¢ user/supervisor bit (U/S) if user-mode processes can access the page 
‚Ä¢ A present bit indicates whether this page is in physical memory or on disk (i.e., it has been swapped out). 
![[Pasted image 20251018112254.png]]

---
## Memory Paging Performance

Page tables can get terribly large, for example consider a 32-bit address space, with 4KB pages:
```
20-bit VPN and 12-bit offset (enough to point to 4K bytes). 

A 20-bit VPN implies that there are 220 translations that the OS would have to manage for each process (that‚Äôs roughly a million). 

If a page table entry (PTE) is 4 bytes then we need 4MB per process. 

If 100 process run in a system then the OS requires 400 MB just for memory.
```
Page tables are store in memory and each memory translation requires two accesses at least. 

---
## Translation-Lookaside Buffer (TLB)

A TLB is part of the chip‚Äôs memory-management unit (MMU). #keyTermDefinition 
- A hardware cache of popular virtual-to-physical address translations thus address-translation cache. 
- The hardware first checks the TLB for a translation. 
- Reduce slow memory access. 

If a page is not in the TLB, i.e. TLB miss, this can trigger a TLB update. 
- Which entry is replaced: Least Recently Used, Least Popular‚Ä¶ 

Who manages a TLB miss? 
- X86 and CISC architecture handle this in hardware. 
- RISC architecture, like MIPS, use software TLB miss handlers.
---